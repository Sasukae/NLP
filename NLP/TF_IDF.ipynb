{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3908d535",
   "metadata": {},
   "source": [
    "## TF-IDF: Exercises\n",
    "Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    "\n",
    "In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    "\n",
    "For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    "\n",
    "We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms.\n",
    "\n",
    "About Data: Emotion Detection\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "This data consists of two columns. - Comment - Emotion\n",
    "\n",
    "Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "As there are only 3 classes, this problem comes under the Multi-Class Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2011fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0633c1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5937, 2),\n",
       "                                              Comment Emotion\n",
       " 0  i seriously hate one subject to death but now ...    fear\n",
       " 1                 im so full of life i feel appalled   anger\n",
       " 2  i sit here to write i start to dig out my feel...    fear\n",
       " 3  ive been really angry with r and i feel like a...     joy\n",
       " 4  i feel suspicious if there is no one outside l...    fear,\n",
       " joy      2000\n",
       " anger    2000\n",
       " fear     1937\n",
       " Name: Emotion, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Emotion_classify_Data.csv\")\n",
    "data.shape,data.head(),data.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce43e930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2000\n",
       "2    2000\n",
       "1    1937\n",
       "Name: Emotion_num, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Emotion_num\"] = data[\"Emotion\"].map({'joy':0,\"fear\":1,\"anger\":2})\n",
    "data.Emotion_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af843764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4749,),\n",
       " (1188,),\n",
       " 0    400\n",
       " 2    400\n",
       " 1    388\n",
       " Name: Emotion_num, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data.Comment,data.Emotion_num,test_size = 0.2,random_state = 2022,stratify = data.Emotion_num)\n",
    "X_train.shape,X_test.shape,y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c5205",
   "metadata": {},
   "source": [
    "## Attempt 1 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "using CountVectorizer with only trigrams.\n",
    "use RandomForest as the classifier.\n",
    "print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f79f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.26      0.36       400\n",
      "           1       0.37      0.79      0.50       388\n",
      "           2       0.55      0.25      0.34       400\n",
      "\n",
      "    accuracy                           0.43      1188\n",
      "   macro avg       0.50      0.43      0.40      1188\n",
      "weighted avg       0.50      0.43      0.40      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_BOW = Pipeline([\n",
    "    (\"vectorizer\",CountVectorizer(ngram_range= (3,3))),\n",
    "    (\"rf_model\",RandomForestClassifier())\n",
    "])\n",
    "rf_BOW.fit(X_train,y_train)\n",
    "y_pred = rf_BOW.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70360a1",
   "metadata": {},
   "source": [
    "## Attempt 2 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "using CountVectorizer with both unigram and bigrams.\n",
    "use Multinomial Naive Bayes as the classifier.\n",
    "print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f983b80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       400\n",
      "           1       0.87      0.83      0.85       388\n",
      "           2       0.83      0.88      0.85       400\n",
      "\n",
      "    accuracy                           0.86      1188\n",
      "   macro avg       0.86      0.86      0.86      1188\n",
      "weighted avg       0.86      0.86      0.86      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_BOW = Pipeline([\n",
    "    (\"vectorizer\",CountVectorizer(ngram_range= (1,2))),\n",
    "    (\"rf_model\",MultinomialNB())\n",
    "])\n",
    "NB_BOW.fit(X_train,y_train)\n",
    "y_pred = NB_BOW.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953af149",
   "metadata": {},
   "source": [
    "## Attempt 3 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "using CountVectorizer with both unigram and Bigrams.\n",
    "use RandomForest as the classifier.\n",
    "print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2cab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       400\n",
      "           1       0.93      0.88      0.91       388\n",
      "           2       0.93      0.85      0.89       400\n",
      "\n",
      "    accuracy                           0.89      1188\n",
      "   macro avg       0.90      0.89      0.89      1188\n",
      "weighted avg       0.90      0.89      0.89      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_BOW = Pipeline([\n",
    "    (\"vectorizer\",CountVectorizer(ngram_range= (1,2))),\n",
    "    (\"rf_model\",RandomForestClassifier())\n",
    "])\n",
    "rf_BOW.fit(X_train,y_train)\n",
    "y_pred = rf_BOW.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503dd0d",
   "metadata": {},
   "source": [
    "## Attempt 4 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "using TF-IDF vectorizer for Pre-processing the text.\n",
    "use RandomForest as the classifier.\n",
    "print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2f4fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       400\n",
      "           1       0.91      0.90      0.91       388\n",
      "           2       0.94      0.86      0.90       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_BOW = Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer()),\n",
    "    (\"rf_model\",RandomForestClassifier())\n",
    "])\n",
    "rf_BOW.fit(X_train,y_train)\n",
    "y_pred = rf_BOW.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c60638",
   "metadata": {},
   "source": [
    "### Use text pre-processing to remove stop words, punctuations and apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ebf8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "      <th>pre_proccessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>I seriously hate one subject to death but now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "      <td>I m so full of life I feel appalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>I sit here to write I start to dig out my feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>I ve be really angry with r and I feel like an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>I feel suspicious if there be no one outside l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emotion_num  \\\n",
       "0  i seriously hate one subject to death but now ...    fear            1   \n",
       "1                 im so full of life i feel appalled   anger            2   \n",
       "2  i sit here to write i start to dig out my feel...    fear            1   \n",
       "3  ive been really angry with r and i feel like a...     joy            0   \n",
       "4  i feel suspicious if there is no one outside l...    fear            1   \n",
       "\n",
       "                                 pre_proccessed_text  \n",
       "0  I seriously hate one subject to death but now ...  \n",
       "1                I m so full of life I feel appalled  \n",
       "2  I sit here to write I start to dig out my feel...  \n",
       "3  I ve be really angry with r and I feel like an...  \n",
       "4  I feel suspicious if there be no one outside l...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocessing(text):\n",
    "    doc = nlp(text)\n",
    "    nlp.vocab[\"not\"].is_stop = \"False\"\n",
    "    req_tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop or not token.is_punct:\n",
    "            req_tokens.append(token.lemma_)\n",
    "    return \" \".join(req_tokens)\n",
    "\n",
    "data[\"pre_proccessed_text\"] = data[\"Comment\"].apply(lambda x: preprocessing(x))\n",
    "data.head()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71000ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4749,),\n",
       " (1188,),\n",
       " 0    400\n",
       " 2    400\n",
       " 1    388\n",
       " Name: Emotion_num, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data.pre_proccessed_text,data.Emotion_num,test_size = 0.2,random_state = 2022,stratify = data.Emotion_num)\n",
    "X_train.shape,X_test.shape,y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bcd0bf",
   "metadata": {},
   "source": [
    "## Let's check the scores with our best model till now\n",
    "\n",
    "Random Forest\n",
    "Attempt1 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "using CountVectorizer with both unigrams and bigrams.\n",
    "use RandomForest as the classifier.\n",
    "print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1502eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       400\n",
      "           1       0.94      0.88      0.91       388\n",
      "           2       0.94      0.84      0.89       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_BOW = Pipeline([\n",
    "    (\"vectorizer\",CountVectorizer(ngram_range= (1,2))),\n",
    "    (\"rf_model\",RandomForestClassifier())\n",
    "])\n",
    "rf_BOW.fit(X_train,y_train)\n",
    "y_pred = rf_BOW.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe3d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       400\n",
      "           1       0.91      0.90      0.91       388\n",
      "           2       0.94      0.85      0.89       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_BOW = Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer()),\n",
    "    (\"rf_model\",RandomForestClassifier())\n",
    "])\n",
    "rf_BOW.fit(X_train,y_train)\n",
    "y_pred = rf_BOW.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705a603",
   "metadata": {},
   "source": [
    "## Final Observations\n",
    "As part of this exercise we have trained the data with algorithms like Multinomial Naive Bayes and Random Forest which are most used and provide good results for text related problems.\n",
    "\n",
    "As Machine learning algorithms do not work on text data directly, we need to convert them into numeric vectors and feed that into models while training. For this purpose, we have used Bag of words(unigrams, bigrams, n-grams) and TF-IDF text representation techniques.\n",
    "\n",
    "Key Findings\n",
    "\n",
    "As the n_gram range keeps increasing, there's drastic fall of improvement in performance metrics.\n",
    "\n",
    "There's seen a significant improvement in results before pre-processing and after pre-processing the data.\n",
    "\n",
    "TF-IDF and Bag of words both performed equally well in performance metrics like Recall and F1-score.\n",
    "\n",
    "Random Forest performed quite well when compared to Multinomial Naive Bayes.\n",
    "\n",
    "Machine Learning is like a trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which gives good results and satisfies the requirements like latency, interpretability, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
