{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9dcc4da",
   "metadata": {},
   "source": [
    "## Bag of words: Exercises\n",
    "In this Exercise, you are going to classify whether a given movie review is positive or negative.\n",
    "you are going to use Bag of words for pre-processing the text and apply different classification algorithms.\n",
    "Sklearn CountVectorizer has the inbuilt implementations for Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2b6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9130e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19000, 2),\n",
       "                                               review sentiment\n",
       " 0  I first saw Jake Gyllenhaal in Jarhead (2005) ...  positive\n",
       " 1  I enjoyed the movie and the story immensely! I...  positive\n",
       " 2  I had a hard time sitting through this. Every ...  negative\n",
       " 3  It's hard to imagine that anyone could find th...  negative\n",
       " 4  This is one military drama I like a lot! Tom B...  positive)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"movies_sentiment_data.csv\")\n",
    "data.shape, data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686ed983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9500\n",
       "1    9500\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Category\"] = data[\"sentiment\"].apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83aad554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data.review,data.Category,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5594f8",
   "metadata": {},
   "source": [
    "## Reference\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e46c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pipeline = Pipeline([\n",
    "    ('vectorizer',CountVectorizer()),\n",
    "    (\"random_model\",RandomForestClassifier(n_estimators=50, criterion='entropy'))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb956634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('random_model',\n",
       "                 RandomForestClassifier(criterion='entropy', n_estimators=50))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a043ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1910\n",
      "           1       0.84      0.82      0.83      1890\n",
      "\n",
      "    accuracy                           0.83      3800\n",
      "   macro avg       0.83      0.83      0.83      3800\n",
      "weighted avg       0.83      0.83      0.83      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = random_pipeline.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac4a95",
   "metadata": {},
   "source": [
    "## Reference \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "937621f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pipeline = Pipeline([\n",
    "    ('vectorizer',CountVectorizer()),\n",
    "    (\"random_model\",KNeighborsClassifier(n_neighbors = 10,metric = \"euclidean\"))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ccab8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      1910\n",
      "           1       0.64      0.62      0.63      1890\n",
      "\n",
      "    accuracy                           0.64      3800\n",
      "   macro avg       0.64      0.64      0.64      3800\n",
      "weighted avg       0.64      0.64      0.64      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNN_pipeline.fit(X_train,y_train)\n",
    "y_pred = KNN_pipeline.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b91e9f",
   "metadata": {},
   "source": [
    "## Reference\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4c3869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1910\n",
      "           1       0.88      0.82      0.85      1890\n",
      "\n",
      "    accuracy                           0.86      3800\n",
      "   macro avg       0.86      0.86      0.85      3800\n",
      "weighted avg       0.86      0.86      0.86      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_pipeline = Pipeline([\n",
    "    ('vectorizer',CountVectorizer()),\n",
    "    (\"random_model\",MultinomialNB())\n",
    "    \n",
    "])\n",
    "NB_pipeline.fit(X_train,y_train)\n",
    "y_pred = NB_pipeline.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595535a",
   "metadata": {},
   "source": [
    "## Can you write some observations of why model like KNN fails to produce good results unlike RandomForest and MultinomialNB?\n",
    "As Machine learning algorithms does not work on Text data directly, we need to convert them into numeric vector and feed that into models while training.\n",
    "In this process, we convert text into a very high dimensional numeric vector using the technique of Bag of words.\n",
    "Model like K-Nearest Neighbours(KNN) doesn't work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of model.\n",
    "The easy calculation of probabilities for the words in corpus(Bag of words) and storing them in contigency table is the major reason for the Multinomial NaiveBayes to be a text classification friendly algorithm.\n",
    "As Random Forest uses Bootstrapping(Row and column Sampling) with many decision tree and overcomes the high variance and overfitting of high dimensional data and also uses feature importance of words for better classifing the categories.\n",
    "Machine Learning is like trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which give good results and satisfy the requirements like latency, interpretability etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
